<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="UTF-8">
        <!-- Begin Jekyll SEO tag v2.8.0 -->
        <title>Birds? Kaggle Competition</title>
        <meta name="generator" content="Jekyll v3.9.3"/>
        <meta property="og:title" content="Birds? Kaggle Competition"/>
        <meta property="og:locale" content="en_US"/>
        <meta name="description" content="A Kaggle Image Classification Competition as CSE 455 Final"/>
        <meta property="og:description" content="A Kaggle Image Classification Competition as CSE 455 Final"/>
        <link rel="canonical" href="https://claussss.github.io/cse455_final/"/>
        <meta property="og:url" content="https://claussss.github.io/cse455_final/"/>
        <meta property="og:site_name" content="Birds? Kaggle Competition"/>
        <meta property="og:type" content="website"/>
        <meta name="twitter:card" content="summary"/>
        <meta property="twitter:title" content="Birds? Kaggle Competition"/>
        <script type="application/ld+json">
            
{"@context":"https://schema.org","@type":"WebSite","description":"A Kaggle Image Classification Competition as CSE 455 Final","headline":"Birds Birds Birds Competition","name":"Birds Birds Birds Competition","url":"https://claussss.github.io/cse455_final/"}
        </script>
        <!-- End Jekyll SEO tag -->
        <link rel="preconnect" href="https://fonts.gstatic.com">
        <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#157878">
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
        <link rel="stylesheet" href="styles.css">
        <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->
        <!-- Setup Google Analytics -->
        <!-- You can set your favicon here -->
        <!-- link rel="shortcut icon" type="image/x-icon" href="/cse455_final/favicon.ico" -->
        <!-- end custom head snippets -->
    </head>
    <body>
        <a href="code.html" class="floating-button">Code</a>
        <a id="skip-to-content" href="#content">Skip to the content.</a>
        <header class="page-header" role="banner">
            <h1 class="project-name">Birds? Kaggle Competition</h1>
            <h2 class="project-tagline">A Kaggle Image Classification Competition as CSE 455 Final</h2>
            <h2 class="project-tagline">Team: Birdy Ensemblers <b><u>(Rank: 1 / 26)</u></b></h2>
            <h3 class="project-tagline2"><a href="https://github.com/hqfang44">Haoquan Fang</a></h2>
            <h3 class="project-tagline2"><a href="https://github.com/QianchengLi2333">Qiancheng Li</a></h2>
            <h3 class="project-tagline2"><a href="https://github.com/zihaohugh">Zihao Wang</a></h2>
            <h3 class="project-tagline2"><a href="https://github.com/calebhuangsea">Cile Huang</a></h2>
            <a href="https://github.com/Birdy-Ensemblers/Birds" class="btn">View on GitHub</a>
        </header>
        <main id="content" class="main-content" role="main">
            <p>For this competition, we are required to solve an image classification task to identify bird species.</p>
            <h1 id="dataset">Dataset</h1>
            <p>
                There are <strong>555</strong>
                classes, approximately <strong>38,000</strong>
                images of varying sizes in the <strong>training</strong>
                set, and <strong>10,000</strong>
                in the <strong>testing</strong>
                set.
            </p>
            <p>Below is some sample data.</p>
            <p>
                <img src="sample.png" alt="sample_data"/>
            </p>
            <p>This histogram of images per class is presented here.</p>
            <p>
                <img src="distribution.png" alt="histogram"/>
            </p>
            <p>total images: 38562</p>
            <p>min class: Dark-eyed Junco (White-winged), num: 10</p>
            <p>max class: White-winged Dove, num: 106</p>
            <p>standard deviation: 22.06846640893006</p>
            <p>Notice that the classes distribution here is uneven. The class with the most instances is ten times the class with the least instances. The standard deviation is also very big.</p>
            <h1 id="balancing-the-data">Balancing the data</h1>
            <p>We have explored two ways to balance the number of instances for each class.</p>
            <h2>(1) Data augmentation:</h2>
            <p>Data augmentation is a technique for artificially increasing the number of samples in the training dataset in order to prevent the model from overfitting. Transformations that are applied should maintain the data’s coherence with the distribution from which it was drawn, as extreme parameters may impede the model’s ability to learn.</p>
            <p>In order to optimize the image loading process, we have resized all the images to 256x256 and stored them on an SSD as the new dataset.</p>
            <p>
                <img src="aug.png" alt="Augmentation"/>
            </p>
            <p>We used <b>Resized, Random Crop, Random Horizontal Flip, Random Affine, Random Rotation, Gaussian Blur, Random Gray Scale</b> as transformations for train data.</p>
            <p>And we only used <b>Resized, Center Crop</b> as transformations for test data.</p>
            <h2>(2) Class weights:</h2>
            <p>We realize in the train dataset, some classes only have little amount of data comparing to other classes. If we trained the model without any preprocessing, the model will have poor performance on these minority classes.</p>
            <p>So we used <b>Weighted Random Sampler</b> on the train data to solve this problem, where we assign classes that have more input data with a smaller weight, and assign minority classes with higher weight.</p>
            <p>
                <img src="weight.png" alt="Weighted Random Sampler"/>
            </p>
            <h1 id="training">Training</h1>
            <p>
                We make use of <strong>PyTorch</strong>
                as our principal ML framework. The only components taken from preexisting work are the data_processing function and the training loop, which were taken from the following <a href="https://colab.research.google.com/drive/1kHo8VT-onDxbtS3FM77VImG35h_K_Lav?usp=sharing">tutorial</a>
                .
            </p>
            <h2 id="model">Model</h2>
            <p>We have been experimenting with various versions of ResNet, such as Resnet18, ResNet101, and ResNet152. However, Resnet18 was deemed too small to learn complex features, while ResNet101 and 152 were too large, leading to overfitting. Ultimately, ResNet50 was chosen as the ideal balance between generalization and data learning. We attempted to add a self-attention mechanism to the ResNet50 model, but it did not yield better performance, thus the attention block was omitted to reduce training time. Variations of ResNet50 such as ResNetX50, which implements certain optimizations, were trialled, yet the performance was not better than that of the pure ResNet50. This is because the quality of the pretrained weights on ImageNet for ResNetX50 was significantly worse than for the pure version. As a result, for the remainder of this blog post, the pure ResNet50 pretrained on ImageNet will be utilized.</p>
            <h2 id="hyperparameters">Hyperparameters</h2>
            <p>
                In order to monitor the performance of the model, we have created a <strong>validation dataset</strong>
                comprising <strong>20%</strong>
                of the training dataset. As the principal performance metric, we utilize <strong>accuracy</strong>
                and CrossEntropy as the loss function. As the optimizer, we employ <strong>SGD</strong>
                with <strong>custom weight decay and momentum</strong>
                . We have tried different batch sizes, and it didn’t influence the performance much although smaller batch sizes tend to help to prevent overfitting. Thus, we used <strong>batch size 64</strong>
                to maximum load our GPU and prevent the model from overfitting.
            </p>
            <h2 id="progressive-resizing">Progressive resizing</h2>
            <p>Progressive resizing is a technique to improve the performance of a model by gradually increasing the resolution of the input images during training.</p>
            <p>Initially, we trained the model on 128x128 images for 5 epochs with a learning rate of 0.01. Following this, we will continue to train the same model on 224x224 images for 30 epochs, with the learning rate decreasing to 0.001 at the 10th epoch and 0.0001 at the 17th epoch. The weight decay and momentum will remain stable at 0.0005 and 0.9, respectively.</p>
            <p>We have experimented with various Pytorch schedulers, however, the manually adjusted learning rate produced the most desirable results.</p>
            <h1 id="evaluation">Evaluation</h1>
            <p>Prior to evaluating the model on the test dataset, we have retrained it on the entirety of the dataset without dividing into a validation set.</p>
            <h2 id="tta">TTA</h2>
            <p>TTA stands for Test Time Augmentation, which is a technique used in machine learning to improve the accuracy of a model’s predictions. It involves applying data augmentation techniques to the test data during the inference stage, which can help to reduce overfitting and improve the model’s ability to generalize to new data.
In our implementation, we apply the same transforms we used for training to every test image four times, and make a prediction for each augmented image. We then average the final class probabilities, resulting in a more stable prediction. This yields an approximate 2% increase in accuracy.</p>
            <p>The final pipeline achieved a score of 83% on the test set.</p>
            <p>
                <a href="">Video Presentation</a>
            </p>
            <footer class="site-footer">
                <span class="site-footer-owner">
                    <a href="https://github.com/Claussss/cse455_final">cse455_final</a>
                    is maintained by <a href="https://github.com/Claussss">Claussss</a>
                    .
                </span>
                <span class="site-footer-credits">
                    This page was generated by <a href="https://pages.github.com">GitHub Pages</a>
                    .
                </span>
            </footer>
        </main>
    </body>
</html>
